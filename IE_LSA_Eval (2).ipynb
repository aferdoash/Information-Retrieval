{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval from Domain Corpus\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Python 2.7\n",
    "* scikit-learn\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "To build an information retrieval system which, given a user query shows up the most relevant query present in its database. Currently, the model is able to handle only simple queries. Compound queries will be dealt in a later version.\n",
    "\n",
    "\n",
    "## Solution Approach\n",
    "\n",
    "In this case, we selected a domain, banking. The bank regulation manual was taken as a reference document for creating a  training data (http://www.bsp.gov.ph/downloads/regulations/morb/morb1.pdf). General FAQs were taken from ICICI Bank (http://www.icicibank.com/Personal-Banking/faq/index.page). For making the FAQs more generally applicable rather than being bank specfic (in our case ICICI specific),  all instances of 'ICICI bank' mentions in the corpus were removed and answers were modified. \n",
    "\n",
    "\n",
    "The steps involved in building the model were as follows :-\n",
    "\n",
    "### Training Data\n",
    "\n",
    "*\tBuild the corpus based on available banking text files\n",
    "*\tExtract category name (here:Banking) based on file name\n",
    "*\tStemming of words in the corpus and removal of stop words\n",
    "*\tVectorization of corpus based on TF-IDF\n",
    "*\tSVD on TFIDF matrix for dimensionality reduction\n",
    "\n",
    "### Test Data\n",
    "\n",
    "*\tGet the user query in string format\n",
    "*\tTransform user query to TFIDF vector after stemming and stopwords removal\n",
    "*   Transform user query TFIDF vector to reduced dimensions\n",
    "      \n",
    "### Information retrieval\n",
    " \n",
    "*    Rank documents in decreasing order of query-document cosine similarities. \n",
    "*    If the best ranked document belongs to the FAQ corpus (rather than the General corpus) \n",
    "     and if the corresponding cosine similarity is > 0.1, then return the corresponding FAQ question id  \n",
    "  \n",
    "In an alternate model, we also tested the model with multiple synonyms of query keywords based on WordNet but the results were similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus was taken from a bank manual (Banking_General) and ICICI Bank FAQs (Banking_FAQs) are read in. The corresponding paths to these files needs to be changed accordingly. \n",
    "The category name is extracted from the file name for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\Desktop\\BOT')\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import re\n",
    "\n",
    "#load the corpus\n",
    "corpus=[]\n",
    "list_of_files_1=glob.glob(r'.\\Banking_General\\*.txt')\n",
    "for file_name in list_of_files_1:\n",
    "    FI = io.open(file_name,'r',encoding='latin-1')\n",
    "    corpus.append(FI.read())\n",
    "\n",
    "#Getting the category name from a file path \n",
    "file_path1 = (list_of_files_1[0])\n",
    "locate_end = file_path1.index('_')\n",
    "locate_start = file_path1.rfind('\\\\',0,locate_end)\n",
    "category = file_path1[(locate_start+1):locate_end]\n",
    "\n",
    "#load the faqs & name each faq appropriately\n",
    "list_of_files_2=glob.glob(r'.\\Banking_FAQ\\*.txt')\n",
    "queryID = {}\n",
    "idx =0\n",
    "for file_name in list_of_files_2:\n",
    "    FI = io.open(file_name,'r',encoding='latin-1').read()\n",
    "    for line in FI.split('\\n'):\n",
    "        corpus.append(line)\n",
    "        corpusID = len(corpus)-1\n",
    "        idx = idx+1\n",
    "        quesID = str(idx)\n",
    "        queryID[corpusID]=quesID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the corpus to generate TFIDF Matrix\n",
    "A instance of TfIdf Vectorizer was created to perform necessary processing of the training corpus. Under this processing we performed stemming of words and removal of stopwords. The stopwords list used here are from NLTK's corpus and an additional stopwords list (Stoplist.txt) created by us. ngrams uptil 5 were used in this analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Define stemming class\n",
    "class PorterStemming(object):\n",
    "         def __init__(self):\n",
    "             #self.wnl = WordNetLemmatizer()\n",
    "              self.wnl = PorterStemmer()\n",
    "         def __call__(self, doc):\n",
    "             return [self.wnl.stem(t) for t in word_tokenize(doc)]\n",
    "\n",
    "#Define Stopwords list \n",
    "stop_list = [line.rstrip('\\n') for line in open('.\\stopwords\\Stoplist.txt','r+')]\n",
    "extra_stopwords = set(stop_list)\n",
    "stops = set(stopwords.words('english')) | extra_stopwords\n",
    "\n",
    "\n",
    "#Define TFIDF Vectorizer\n",
    "tfidfvec=TfidfVectorizer(corpus,decode_error='ignore',stop_words= stops,ngram_range=(1,5), tokenizer=PorterStemming())\n",
    "trainset_idf_vectorizer=tfidfvec.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction using SVD\n",
    "\n",
    "Singular Value Decomposition (SVD) was performed on the TFIDF matrix generated from the training corpus to extract only the most important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=150, algorithm='randomized',n_iter=15, random_state=42)\n",
    "train_lsa = svd.fit_transform(trainset_idf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform user query and extract document similarities\n",
    "\n",
    "We next define a function to process a user query and return the question id of the most relevant document. Specifically, we transform the query based on the Tfidf instance and SVD instance described above. Cosine similarities are then extracted to compute distances between each document and user query. The most similar document, if belonging to the FAQ corpus and above a threshhold distance is returned as the best match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def process_query(query):\n",
    "    query=query.lower()\n",
    "    query = [query]\n",
    "    test=tfidfvec.transform(query).toarray()\n",
    "    lsa_test=svd.transform(test)\n",
    "    cosine_similarities = linear_kernel(lsa_test, train_lsa).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-3:-1]\n",
    "    top_result_index = related_docs_indices[0]\n",
    "    if (top_result_index > 95) & (cosine_similarities[top_result_index] > 0.1):\n",
    "        return queryID[top_result_index]\n",
    "    else:\n",
    "        return  \"Sorry, I don't have an answer for that\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corresponding FAQ id: 20 \n",
      "\n",
      "The user query was - \n",
      " what is the maximum amount I can withdraw in a day at an ATM \n",
      "\n",
      "The matched FAQ is - \n",
      " What is the maximum cash I can withdraw at an ATM in a single day ? Yes, banks set limit for cash withdrawal by customers. The cash withdrawal limit for use at the ATM of the issuing bank is set by the bank during the issuance of the card. This limit is displayed at the respective ATM locations.For cash withdrawals at other bank ATMs, banks have decided to maintain a limit of Rs 10,000/- per transaction. This information is displayed at the ATM location \n"
     ]
    }
   ],
   "source": [
    "query=\"what is the maximum amount I can withdraw in a day at an ATM\"\n",
    "result = int(process_query(query))\n",
    "print \"The corresponding FAQ id: %d \\n\" % result\n",
    "print \"The user query was - \\n %s \\n\" % query\n",
    "print \"The matched FAQ is - \\n %s \" % corpus[95+20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "\n",
    "We will now evaluate the model based on a Test Corpus by checking for how many FAQs, the model returned the right matching query. For this purpose, we have two Test Corpus: 1) Contains exact matching query 2) Contains queries which are semantically similar. We evaluate the performance of the model separately on these two corpi.\n",
    "\n",
    "### PART 1: EXACTLY MATCHING QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testCorpus = []\n",
    "file_name = r'.\\TestCorpus\\TestFAQs_Direct.txt'\n",
    "testFile = io.open(file_name,'r',encoding='latin-1').read()\n",
    "for line in testFile.split('\\n'):\n",
    "     testCorpus.append(line)\n",
    "\n",
    "def process_testCorpus(testCorpus):\n",
    "    all_results = []\n",
    "    for each_FAQ in testCorpus:\n",
    "        all_results.append(process_query(each_FAQ))\n",
    "    return all_results\n",
    "\n",
    "all_results = process_testCorpus(testCorpus)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 21 Exact Questions, accuracy  : 0.904762\n"
     ]
    }
   ],
   "source": [
    "qa= []\n",
    "inds = []\n",
    "\n",
    "for i,query in enumerate(testCorpus):\n",
    "    try:\n",
    "        ans_inds = int(all_results[i])\n",
    "        a = corpus[95+ans_inds]\n",
    "    except ValueError:\n",
    "        ans_inds = 9999\n",
    "        a = all_results[i]\n",
    "    qa.append(query + ' MATCHING QUERY :  ' + a)\n",
    "    inds.append(ans_inds)\n",
    "    \n",
    "resultFile = io.open(r'.\\TestCorpus\\Results_Direct.txt','w',encoding='UTF-8')\n",
    "\n",
    "for line in qa:\n",
    "    resultFile.write(\"%s\\n\" % line)\n",
    "    \n",
    "    \n",
    "answerFile = io.open(r'.\\TestCorpus\\Answers_Direct.txt','r',encoding='latin-1')\n",
    "\n",
    "i=0\n",
    "score = 0.\n",
    "for line in answerFile:\n",
    "     line = (line.strip('\\n')).encode('ascii','ignore')\n",
    "     line = line.split()\n",
    "     line= map(int,line)\n",
    "     if inds[i] in line:\n",
    "        score = score+1\n",
    "     i=i+1\n",
    "accuracy = score/len(inds)\n",
    "print \"For %d Exact Questions, accuracy  : %f\" % (len(inds), accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2: Semantically similar queries\n",
    "\n",
    "We now test the model against user queries that have semantically similar but not an exactly matching query in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testCorpus = []\n",
    "file_name = r'.\\TestCorpus\\TestFAQs_Indirect.txt'\n",
    "testFile = io.open(file_name,'r',encoding='latin-1').read()\n",
    "for line in testFile.split('\\n'):\n",
    "     testCorpus.append(line)\n",
    "\n",
    "def process_testCorpus(testCorpus):\n",
    "    all_results = []\n",
    "    for each_FAQ in testCorpus:\n",
    "        all_results.append(process_query(each_FAQ))\n",
    "    return all_results\n",
    "\n",
    "all_results = process_testCorpus(testCorpus)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 21 Indirect Questions, accuracy  : 0.714286\n"
     ]
    }
   ],
   "source": [
    "qa= []\n",
    "inds = []\n",
    "\n",
    "for i,query in enumerate(testCorpus):\n",
    "    try:\n",
    "        ans_inds = int(all_results[i])\n",
    "        a = corpus[95+ans_inds]\n",
    "    except ValueError:\n",
    "        ans_inds = 9999\n",
    "        a = all_results[i]\n",
    "    qa.append(query + ' MATCHING QUERY :  ' + a)\n",
    "    inds.append(ans_inds)\n",
    "    \n",
    "resultFile = io.open(r'.\\TestCorpus\\Results_Indirect.txt','w',encoding='UTF-8')\n",
    "\n",
    "for line in qa:\n",
    "    resultFile.write(\"%s\\n\" % line)\n",
    "\n",
    "    \n",
    "answerFile = io.open(r'.\\TestCorpus\\Answers_Indirect.txt','r',encoding='latin-1')\n",
    "\n",
    "i=0\n",
    "score = 0.\n",
    "for line in answerFile:\n",
    "     line = (line.strip('\\n')).encode('ascii','ignore')\n",
    "     line = line.split()\n",
    "     line= map(int,line)\n",
    "     if inds[i] in line:\n",
    "        score = score+1\n",
    "     i=i+1\n",
    "accuracy = score/len(inds)\n",
    "print \"For %d Indirect Questions, accuracy  : %f\" % (len(inds), accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
